package cn.itcast.lucene;

import java.io.File;

import javax.activation.FileDataSource;

import org.apache.commons.io.FileUtils;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.cjk.CJKAnalyzer;
import org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.LongField;
import org.apache.lucene.document.StoredField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.RAMDirectory;
import org.apache.lucene.util.Version;
import org.junit.Test;
import org.wltea.analyzer.lucene.IKAnalyzer;

public class FirstLucene {

	//创建索引库
	@Test
	public void createIndex() throws Exception {
		//指定索引库存放的位置
		String indexPath = "F:\\学习\\lucene\\LuceneFirst14_index";
		//将索引库存放到内存中
		//Directory directory = new RAMDirectory();
		//存放到文件系统中
		Directory directory = FSDirectory.open(new File(indexPath));
		//创建分析器对象
//		Analyzer analyzer = new StandardAnalyzer();
		Analyzer analyzer = new IKAnalyzer();
		//创键IndexWriterconfig对象
		//第一个参数：Lucene使用的版本
		//第二个参数：分析器对象
		IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, analyzer);
		//创建Indexwriter对象
		IndexWriter indexWriter = new IndexWriter(directory, config);
		//遍历原始文档文件夹下的所有文件将文件内容读取到程序中
		File path = new File("F:\\学习\\lucene\\searchsource");
		for (File file : path.listFiles()) {
			//创建Document对象
			Document document = new Document();
			//获得文件名
			String fileName = file.getName();
			//获得文件内容
			String fileContent = FileUtils.readFileToString(file);
			//文件路径
			String filePath = file.getPath();
			//文件的大小
			long fileSize = FileUtils.sizeOf(file);
			//向文档中添加域
			//第一个参数：域名
			//第二个参数：域的值
			//第三个参数：是否存储Store.YES存储	Store.NO 不存储
			Field fileNameField = new TextField("filename", fileName, Store.YES);
			Field fileContentField = new TextField("content", fileContent, Store.YES);
			Field filePathField = new StoredField("path", filePath);
			Field fileSizeField = new LongField("size", fileSize, Store.YES);
			//添加到文档对象中
			document.add(fileNameField);
			document.add(fileContentField);
			document.add(filePathField);
			document.add(fileSizeField);
			
			//将document写入索引库
			indexWriter.addDocument(document);
			
		}
		indexWriter.close();
		
	}
	
	@Test
	public void searchIndex() throws Exception {
		//索引库存放的路径
		Directory directory = FSDirectory.open(new File("F:\\学习\\lucene\\LuceneFirst14_index"));
		//创建indexreader对象
		IndexReader indexReader = DirectoryReader.open(directory);
		//创建indexsearcher
		IndexSearcher indexSearcher = new IndexSearcher(indexReader);
		//创建查询
		Query query = new TermQuery(new Term("content", "apache"));
		System.out.println(query);
		//执行查询
		//第一个参数是查询对象
		//第二个参数：返回结果的最大值。
		TopDocs topDocs = indexSearcher.search(query, 2);
		//查询结果的总数量
		System.out.println("查询结果的总数量：" + topDocs.totalHits);
		//遍历查询结果
		for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
			//scoreDoc.doc文档的唯一id可以根据这个id取document对象
			//使用indexsearcher对象的doc方法从索引库中取document对象，需要document对象的id
			Document document = indexSearcher.doc(scoreDoc.doc);
			//取文档的属性内容
			System.out.println(document.get("filename"));
//			System.out.println(document.get("content"));
			System.out.println(document.get("path"));
			System.out.println(document.get("size"));
		}
		indexReader.close();
	}
	@Test
	//测试分析器的分词效果
	public void testTokenStream() throws Exception {
		//创建分析器对象
//		Analyzer analyzer = new StandardAnalyzer();
//		Analyzer analyzer = new CJKAnalyzer();
//		Analyzer analyzer = new SmartChineseAnalyzer();
		Analyzer analyzer = new IKAnalyzer();
		//获得tokenstream
		TokenStream tokenStream = analyzer.tokenStream("test", "传智播客是apache软件基金会一个开放源代码的全文检索引擎工具包,是一个全文检索引擎的架");
		//调整指针至最顶端
		tokenStream.reset();
		//获得当前词的一个引用
		CharTermAttribute termAttribute = tokenStream.addAttribute(CharTermAttribute.class);
		//获得当前词的偏移量引用
		OffsetAttribute offsetAttribute = tokenStream.addAttribute(OffsetAttribute.class);
		//遍历tokenstream
		while(tokenStream.incrementToken()) {
			//取当前词的开始位置
			System.out.println("start->" + offsetAttribute.startOffset());
			//取当前词内容
			System.out.println(termAttribute);
			//当前词的结束位置
			System.out.println("end->" + offsetAttribute.endOffset());
		}
		tokenStream.close();
	}
	
}


第二个代码：
package cn.itcast.lucene;

import java.io.File;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;
import org.junit.Test;
import org.wltea.analyzer.lucene.IKAnalyzer;


public class IndexManager {

	private IndexWriter getIndexWriter() throws Exception {
		//指定索引库存放的位置
		String indexPath = "F:\\学习\\lucene\\LuceneFirst14_index";
		//将索引库存放到内存中
		//Directory directory = new RAMDirectory();
		//存放到文件系统中
		Directory directory = FSDirectory.open(new File(indexPath));
		//创建分析器对象
		Analyzer analyzer = new IKAnalyzer();
		//创键IndexWriterconfig对象
		//第一个参数：Lucene使用的版本
		//第二个参数：分析器对象
		IndexWriterConfig config = new IndexWriterConfig(Version.LATEST, analyzer);
		//创建Indexwriter对象
		IndexWriter indexWriter = new IndexWriter(directory, config);
		return indexWriter;
	}
	//向索引库添加文档
	@Test
	public void addDocument() throws Exception {
		//获得indexwriter对象
		IndexWriter indexWriter = getIndexWriter();
		//创建文档对象
		Document document = new Document();
		//添加域
		Field fileName = new TextField("filename", "新添加的文档设置boost值" , Store.YES);
		Field content = new TextField("content", "2013年10月25日 - Apache Lucene 4.5.1 发布,该版本主要是修复了 8 个 bug,Lucene 是apache软件基金会一个开放源代码的全文检索引擎工具包,是一", Store.NO);
		content.setBoost(10f);
		//添加到document中
		document.add(fileName);
		document.add(content);
		//添加到索引库
		indexWriter.addDocument(document);
		//关闭indexwriter
		indexWriter.close();
		
	}
	
	//删除全部文档
	@Test
	public void deleteAllDocument() throws Exception {
		//获得indexwriter对象
		IndexWriter indexWriter = getIndexWriter();
		//删除全部文档
		indexWriter.deleteAll();
		indexWriter.close();
	}
	//根据查询删除文档
	@Test
	public void deleteDocumentByQuery() throws Exception {
		//获得indexwriter对象
		IndexWriter indexWriter = getIndexWriter();
		//创建一个查询
		Query query = new TermQuery(new Term("content", "java"));
		
		indexWriter.deleteDocuments(query);
	
		indexWriter.close();
	}
	
	@Test
	public void updateDocument() throws Exception {
		//获得indexwriter对象
		IndexWriter indexWriter = getIndexWriter();
		//创建一个新文档
		Document document = new Document();
		//添加域
		Field fileName = new TextField("filename", "新添加的文档" , Store.YES);
		Field content = new TextField("content", "2013年10月25日 - Apache Lucene 4.5.1 发布,该版本主要是修复了 8 个 bug,Lucene 是apache软件基金会一个开放源代码的全文检索引擎工具包,是一", Store.NO);
		document.add(fileName);		
		document.add(content);	
		
		indexWriter.updateDocument(new Term("content", "apache"), document);
		indexWriter.close();
	}
}



第三段代码：
package cn.itcast.lucene;

import java.io.File;
import java.util.HashMap;
import java.util.Map;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.queryparser.classic.MultiFieldQueryParser;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.BooleanClause.Occur;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.MatchAllDocsQuery;
import org.apache.lucene.search.NumericRangeQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.junit.Test;
import org.wltea.analyzer.lucene.IKAnalyzer;

public class IndexSearch {

	private IndexSearcher getIndexSearcher() throws Exception {
		//索引库存放的路径
		Directory directory = FSDirectory.open(new File("F:\\学习\\lucene\\LuceneFirst14_index"));
		//创建indexreader对象
		IndexReader indexReader = DirectoryReader.open(directory);
		//创建indexsearcher
		IndexSearcher indexSearcher = new IndexSearcher(indexReader);
		return indexSearcher;
	}
	
	private void showResult(Query query, IndexSearcher indexSearcher) throws Exception {
		//查询索引库
		TopDocs topDocs = indexSearcher.search(query, 10);
		//查询到结果的总数量
		System.out.println("查询到结果的总数量:" + topDocs.totalHits);
		// 遍历查询结果
		for (ScoreDoc scoreDoc : topDocs.scoreDocs) {
			//获得document对象
			Document document = indexSearcher.doc(scoreDoc.doc);
			System.out.println(document.get("filename"));
//			System.out.println(document.get("content"));
			System.out.println(document.get("size"));
			System.out.println(document.get("path"));
		}
		//关闭indexreader
		indexSearcher.getIndexReader().close();
	}
	
	//根据数值范围查询
	@Test
	public void testNumricRangeQuery() throws Exception {
		//获得indexsearcher对象
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建一个查询对象
		//参数1：查询的域的名称
		//参数2：最小值
		//参数3：最大值
		//参数4：是否包含最小值
		//参数5：是否包含最大值
		Query query = NumericRangeQuery.newLongRange("size", 10l, 1000l, true, true);
		System.out.println(query);
		//执行查询
		showResult(query, indexSearcher);
	}
	
	@Test
	public void testBooleanQuery() throws Exception {
		//获得indexsearcher对象
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建一个查询对象
		BooleanQuery booleanQuery = new BooleanQuery();
		//创建查询条件
		Query query1 = new TermQuery(new Term("content", "java"));
		Query query2 = new TermQuery(new Term("content", "apache"));
		
		booleanQuery.add(query1, Occur.MUST);
		booleanQuery.add(query2, Occur.MUST);
		System.out.println(booleanQuery);
		//执行查询
		showResult(booleanQuery, indexSearcher);
	}
	
	@Test
	public void testMatchAllDocsQuery() throws Exception {
		//获得indexsearcher对象
		IndexSearcher indexSearcher = getIndexSearcher();
		//创建一个查询对象
		Query query = new MatchAllDocsQuery();
		//执行查询
		showResult(query, indexSearcher);
	}
	@Test
	public void testQueryParser() throws Exception {
		//获得indexsearcher对象
		IndexSearcher indexSearcher = getIndexSearcher();
		//使用queryparser来创建查询对象
		//第一个参数：默认搜索的域
		//第二个参数：分析器对象。注意：查询的分析器要和创建索引时使用的分析器一致。
		QueryParser queryParser = new QueryParser("content", new IKAnalyzer());
		Query query = queryParser.parse("apache");
		System.out.println(query);
		//执行查询
		showResult(query, indexSearcher);
	}
	@Test
	public void testMultFieldQueryParser() throws Exception {
		//获得indexsearcher对象
		IndexSearcher indexSearcher = getIndexSearcher();
		//默认域列表
		String[] fields = {"filename","content"};
		//设置不同的域的boost值
		Map<String, Float> boosts = new HashMap<>();
		boosts.put("filename", 20f);
		boosts.put("content", 2f);
		//创建MultiFieldQueryParser对象
		MultiFieldQueryParser queryParser = 
				new MultiFieldQueryParser(fields, new IKAnalyzer(), boosts);
		Query query = queryParser.parse("java");
		System.out.println(query);
		//执行查询
		showResult(query, indexSearcher);
	}
}

